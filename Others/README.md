# DARTS ğŸ¯ playground ğŸ§—â€

### This repo is made for ML2's playground projects
> **ğŸŒ running environment info** <br>
> `python >= 3.6, pytorch == 1.0, and needs CUDA`
> <br><br>
> **Requirements** <br>
>
> `torch`<br>
> `torchvision`<br>
> `graphviz`<br>
> `numpy`<br>
> `tensorboard`<br>
> `tensorboardx`<br>


<br>

### ğŸš€ How to search and train?
> ğŸ² Simply, you can run DARTS search process with <br> &nbsp;&nbsp;&nbsp;&nbsp; `python run.py --name <your_pjt_name> --dataset <data_NAME> --data_path <your_PATH>` <br><br>
> --> ex) `python run.py --name DARTS_test1 --dataset cifar10 --data_path ../data`
> 
> If you need customize some parameters, check `python run.py -h`
>
> This process can visualize by using tensorboard <br>
> (After execute run.py)`tensorboard --logdir=./searchs/<your_pjt_name>/tb --port=6006`<br>
>
> You can visualize arch_graph with `python visualize.py <arch's Genotype>` 
> 

<br>

### ğŸ”— Process description. ğŸ¥šğŸ£ğŸ¥
#### 1. start setting
> 1. Get some arguments in shell
> 2. Set training environment such as using GPU
> 3. Define model(Network) and optimizers
> 4. Make Dataset(dataloader) -- cifar10
> 5. Set lr scheduler
> 6. and Define arch 


#### 2. under training (alpha searching)
>```
1. â—‹ epoch loop
2. â”œâ”€ set lr scheduler 
3. â”œâ”€ set genotype
4. â”œâ”€â—‹ training loop (start step loop (batch streaming))
5. â”‚ â”œâ”€ dataset setting
6. â”‚ â”œâ”€â—‹ arch stepping (architecture weight)
7. â”‚ â”‚ â”œâ”€ run virtual step & get gradients
8. â”‚ â”‚ â”œâ”€ compute hessian
9. â”‚ â”‚ â””â”€ update alpha gradient
10.â”‚ â”œâ”€ alpha optimizing
11.â”‚ â”œâ”€ model training
12.â”‚ â””â”€ model fitting()
13.â””â”€ validating loop
14. output best model's genotype
```

#### 3. under training (arch searching)



This project is referred from

- DARTS https://arxiv.org/abs/1806.09055

- git https://github.com/quark0/darts
